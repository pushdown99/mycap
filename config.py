parameters = {
}

coco2014_cfg = {
  'name':               'coco2014',
  'dataset_dir':        'datasets/COCO',
  'images_dir':        ['datasets/COCO/train2014', 'datasets/COCO/val2014' ],
  'train_file':         'datasets/COCO/annotations/captions_train2014.json',
  'valid_file':         'datasets/COCO/annotations/captions_val2014.json',
  'train_limit':        3000000,
  'valid_limit':        3000000,
  'val_test_split':     0.9,
  'number_of_captions': 5,
  'example_image':      'datasets/COCO/train2014/COCO_train2014_000000247789.jpg',
  'example_id':         'COCO_train2014_000000247789',
}

coco2017_cfg = {
  'name':               'coco2017',
  'dataset_dir':        'datasets/COCO',
  'images_dir':        ['datasets/COCO/train2017', 'datasets/COCO/val2017'],
  'train_file':         'datasets/COCO/annotations/captions_train2017.json',
  'valid_file':         'datasets/COCO/annotations/captions_val2017.json',
  'train_limit':        3000000,
  'valid_limit':        3000000,
  'val_test_split':     0.9,
  'number_of_captions': 5,
  'example_image':      'datasets/COCO/train2017/COCO_train2017_000000247789.jpg',
  'example_id':         'COCO_train2017_000000247789',
}


flickr8k_cfg = {
  'name':               'flickr8k',
  'dataset_dir':        'datasets/Flickr8k',
  'images_dir':        ['datasets/Flickr8k/Flicker8k_Dataset'],
  'caption_file':       'datasets/Flickr8k/Flickr8k.token.txt',
  'train_file':         'datasets/Flickr8k/Flickr_8k.trainImages.txt',
  'valid_file':         'datasets/Flickr8k/Flickr_8k.devImages.txt',
  'test_file':          'datasets/Flickr8k/Flickr_8k.testImages.txt',
  'train_limit':        3000000,
  'valid_limit':        3000000,
  'test_limit':         3000000,
  'number_of_captions': 5,
  'example_image':      'datasets/Flickr8k/Flicker8k_Dataset/667626_18933d713e.jpg',
  'example_id':         '667626_18933d713e',
}

nia0403e_cfg = {
  'name':               'nia0403e',
  'data_dir':           'datasets/NIA/annotations',
  'json_dir':           'datasets/NIA/annotations/4-3',
  'images_dir':        ['datasets/NIA/images'],
  'caption_file':       'datasets/NIA/annotations/nia0403.token.eng.txt',
  'train_file':         'datasets/NIA/annotations/nia0403.trainImages.txt',
  'valid_file':         'datasets/NIA/annotations/nia0403.devImages.txt',
  'test_file':          'datasets/NIA/annotations/nia0403.testImages.txt',
  'train_limit':        8000,
  'valid_limit':        2000,
  'test_limit':         1000,
  'train_val_split':    0.8,
  'val_test_split':     0.8,
  'number_of_captions': 5,
  'example_image':      'datasets/NIA/images/IMG_0250492_pan(pan).jpg',
  'example_id':         'IMG_0250492_pan(pan)',
}

nia0403k_cfg = {
  'name':               'nia0403k',
  'data_dir':           'datasets/NIA/annotations',
  'json_dir':           'datasets/NIA/annotations/4-3',
  'images_dir':        ['datasets/NIA/images'],
  'caption_file':       'datasets/NIA/annotations/nia0403.token.kor.txt',
  'train_file':         'datasets/NIA/annotations/nia0403.trainImages.txt',
  'valid_file':         'datasets/NIA/annotations/nia0403.devImages.txt',
  'test_file':          'datasets/NIA/annotations/nia0403.testImages.txt',
  'train_limit':        3000000,
  'valid_limit':        3000000,
  'test_limit':         3000000,
  'train_val_split':    0.8,
  'val_test_split':     0.8,
  'number_of_captions': 5,
  'example_image':      'datasets/NIA/images/IMG_0250492_pan(pan).jpg',
  'example_id':         'IMG_0250492_pan(pan)',
}

nia0404e_cfg = {
  'name':               'nia0404e',
  'dataset_dir':        'datasets/NIA/annotations',
  'images_dir':        ['datasets/NIA/images'],
  'caption_file':       'datasets/NIA/annotations/nia0404.token.eng.txt',
  'train_file':         'datasets/NIA/annotations/nia0404.trainImages.txt',
  'valid_file':         'datasets/NIA/annotations/nia0404.devImages.txt',
  'test_file':          'datasets/NIA/annotations/nia0404.testImages.txt',
  'train_limit':        8000,
  'valid_limit':        2000,
  'test_limit':         1000,
  'train_val_split':    0.8,
  'val_test_split':     0.8,
  'number_of_captions': 5,
  'example_image':      'datasets/NIA/images/IMG_0250492_pan(pan).jpg',
  'example_id':         'IMG_0250492_pan(pan)',
}

nia0404k_cfg = {
  'name':               'nia0404k',
  'dataset_dir':        'datasets/NIA/annotations',
  'images_dir':        ['datasets/NIA/images'],
  'caption_file':       'datasets/NIA/annotations/nia0404.token.kor.txt',
  'train_file':         'datasets/NIA/annotations/nia0404.trainImages.txt',
  'valid_file':         'datasets/NIA/annotations/nia0404.devImages.txt',
  'test_file':          'datasets/NIA/annotations/nia0404.testImages.txt',
  'train_limit':        8000,
  'valid_limit':        2000,
  'test_limit':         1000,
  'train_val_split':    0.8,
  'val_test_split':     0.8,
  'number_of_captions': 5,
  'example_image':      'datasets/NIA/images/IMG_0250492_pan(pan).jpg',
  'example_id':         'IMG_0250492_pan(pan)',
}

voc2007_cfg = {
  'name':               'voc2007',
  'dataset_dir':        'datasets/VOCdevkit/VOC2007',
  'images_dir':        ['datasets/VOCdevkit/VOC2007/JPEGImages'],
  'caption_file':       'datasets/NIA/annotations/nia0404.token.kor.txt',
  'train_file':         'datasets/NIA/annotations/nia0404.trainImages.txt',
  'valid_file':         'datasets/NIA/annotations/nia0404.devImages.txt',
  'test_file':          'datasets/NIA/annotations/nia0404.testImages.txt',
  'train_limit':        8000,
  'valid_limit':        2000,
  'test_limit':         1000,
  'train_val_split':    0.8,
  'val_test_split':     0.8,
  'number_of_captions': 5,
  'example_image':      'datasets/NIA/images/IMG_0250492_pan(pan).jpg',
  'example_id':         'IMG_0250492_pan(pan)',
}

voc2012_cfg = {
  'name':               'voc2012',
  'dataset_dir':        'datasets/VOCdevkit/VOC2012',
  'images_dir':        ['datasets/VOCdevkit/VOC2012/JPEGImages'],
  'caption_file':       'datasets/NIA/annotations/nia0404.token.kor.txt',
  'train_file':         'datasets/NIA/annotations/nia0404.trainImages.txt',
  'valid_file':         'datasets/NIA/annotations/nia0404.devImages.txt',
  'test_file':          'datasets/NIA/annotations/nia0404.testImages.txt',
  'train_limit':        8000,
  'valid_limit':        2000,
  'test_limit':         1000,
  'train_val_split':    0.8,
  'val_test_split':     0.8,
  'number_of_captions': 5,
  'example_image':      'datasets/NIA/images/IMG_0250492_pan(pan).jpg',
  'example_id':         'IMG_0250492_pan(pan)',
}


vgg16_cfg = {
  'name':                       'vgg16',
  'model':                      'rnn_model1',

  'verbose':                    True,
  'image_size':                 224,
  'num_of_epochs':              10,
  'batch_size':                 64,
  'buffer_size':                1000,
  'embedding_size':             256,
  'units':                      256,
  'input_size':                 4096,
  'top_k':                      5000,
  'features_shape':             512,
  'attention_features_shape':   64,
}

inceptionv3_cfg = {
  'name':                       'inceptionv3',
  'model':                      'rnn_model1',

  'verbose':                    True,
  'image_size':                 299,
  'num_of_epochs':              10,
  'batch_size':                 64,
  'buffer_size':                1000,
  'embedding_size':             256,
  'units':                      256,
  'input_size':                 4096,
  'top_k':                      5000,
  'features_shape':             512,
  'attention_features_shape':   64,
}

efficientb0_cfg = {
  'name':                       'efficientb0',
  'model':                      'rnn_model1',

  'verbose':                    True,
  'image_size':                 224,
  'num_of_epochs':              10,
  'batch_size':                 64,
  'buffer_size':                1000,
  'embedding_size':             256,
  'units':                      256,
  'input_size':                 4096,
  'top_k':                      5000,
  'features_shape':             512,
  'attention_features_shape':   64,

  'IMAGE_SHAPE':  			    (299,299),
  'MAX_VOCAB_SIZE':  			2000000,
  'SEQ_LENGTH':      			25,
  'BATCH_SIZE':      			64,
  'SHUFFLE_DIM':     			512,
  'EMBED_DIM':       			512,
  'FF_DIM':          			1024,
  'NUM_HEADS':       			6,
}


voc2007_train_opts = {
  'train':                    True,
#  'load_from':                'fasterrcnn_tf2_best.h5',
  'save_to':                  '',
  'save_best_to':             'fasterrcnn_tf2_best_e1.h5',
  'dataset_dir':              'datasets/VOCdevkit/VOC2007',
  'train_split':              'trainval',
  'eval_split':               'test',
  'cache_images':             '',
  'periodic_eval_samples':    1000,
  'checkpoint_dir':           '',
  'plot':                     '',
  'log_csv':                  '',
  'epochs':                   1,
  'optimizer':                'sgd',
  'learning_rate':            1e-3,
  'clipnorm':                 0.0,
  'momentum':                 0.9,
  'beta1':                    0.9,
  'beta2':                    0.999,
  'weight_decay':             5e-4,
  'dropout':                  0.0,
  'custom_roi_pool':          '',
  'detector_logits':          '',
  'no_augment':               '',
  'exclude_edge_proposals':   '',
  'dump_anchors':             '',
  'debug_dir':                '',
}

voc2007_eval_opts = {
  'eval':                     True,
  'load_from':                'fasterrcnn_tf2_best.h5',
  'save_to':                  '',
  'save_best_to':             'fasterrcnn_tf2_best_e1.h5',
  'dataset_dir':              'datasets/VOCdevkit/VOC2007',
  'train_split':              'trainval',
  'eval_split':               'test',
  'cache_images':             '',
  'periodic_eval_samples':    1000,
  'checkpoint_dir':           '',
  'plot':                     '',
  'log_csv':                  '',
  'epochs':                   1,
  'optimizer':                'sgd',
  'learning_rate':            1e-3,
  'clipnorm':                 0.0,
  'momentum':                 0.9,
  'beta1':                    0.9,
  'beta2':                    0.999,
  'weight_decay':             5e-4,
  'dropout':                  0.0,
  'custom_roi_pool':          '',
  'detector_logits':          '',
  'no_augment':               '',
  'exclude_edge_proposals':   '',
  'dump_anchors':             '',
  'debug_dir':                '',
}

nia0404_train_opts = {
  'train':                    True,
#  'load_from':                'fasterrcnn_tf2_best.h5',
  'save_to':                  '',
  'save_best_to':             'nia_vgg16_fasterrcnn_tf2_best_e1.h5',
  'dataset_dir':              'datasets/NIA',
  'train_split':              'trainval',
  'eval_split':               'test',
  'cache_images':             '',
  'periodic_eval_samples':    1000,
  'checkpoint_dir':           '',
  'plot':                     '',
  'log_csv':                  '',
  'epochs':                   1,
  'optimizer':                'sgd',
  'learning_rate':            1e-3,
  'clipnorm':                 0.0,
  'momentum':                 0.9,
  'beta1':                    0.9,
  'beta2':                    0.999,
  'weight_decay':             5e-4,
  'dropout':                  0.0,
  'custom_roi_pool':          '',
  'detector_logits':          '',
  'no_augment':               '',
  'exclude_edge_proposals':   '',
  'dump_anchors':             '',
  'debug_dir':                '',
}


